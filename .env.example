# Dorothy Configuration
# Copy to .env and fill in your values

# =============================================================================
# LLM Service (for synthesis)
# =============================================================================
# URL of your LLM server (LM Studio, Ollama, etc.)
LLM_BASE_URL=http://192.168.0.149:1234

# Model to use for synthesis
LLM_MODEL=qwen/qwen3-next-80b

# =============================================================================
# Embedding Service (for clustering)
# =============================================================================
# URL of your embedding server (can be same as LLM)
EMBEDDING_BASE_URL=http://192.168.0.149:1234

# Embedding model name
EMBEDDING_MODEL=text-embedding-mxbai-embed-large-v1

# =============================================================================
# AWS / S3 Deployment
# =============================================================================
# S3 bucket for static site hosting
S3_BUCKET=dorothy-news

# AWS region
AWS_REGION=us-east-1

# CloudFront distribution ID (optional, for cache invalidation)
CLOUDFRONT_ID=

# AWS credentials (optional if using ~/.aws/credentials or IAM roles)
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

# =============================================================================
# OpenSearch
# =============================================================================
OPENSEARCH_HOST=localhost
OPENSEARCH_PORT=9200
OPENSEARCH_USERNAME=
OPENSEARCH_PASSWORD=
OPENSEARCH_USE_SSL=false

# =============================================================================
# Pipeline Settings
# =============================================================================
SCHEDULER_FETCH_INTERVAL_MINUTES=60
FETCHER_BATCH_SIZE=50
FETCHER_TIMEOUT=30
